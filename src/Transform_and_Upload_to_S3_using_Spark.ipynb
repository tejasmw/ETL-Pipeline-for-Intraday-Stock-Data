{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ec4ae3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.2\n",
      "Successful S3 put_object response. Status - 200\n",
      "New file uploaded to S3: s3://apple-intraday/AppleIntraday_20240820_104721.csv\n"
     ]
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pymongo import MongoClient\n",
    "from bson import ObjectId\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import lag, expr\n",
    "import boto3\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import io\n",
    "\n",
    "# Step 1: Create a Spark session\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MongoDB to Spark\") \\\n",
    "    .config(\"spark.jars\", \"FILE / WEB LOCATION FOR MONGO-SPARK CONNECTOR\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "\n",
    "# Step 2: MongoDB connection details\n",
    "mongo_uri = \"mongodb://localhost:27017\" #Local Machine, default same for every machine. Can be changed.\n",
    "database_name = \"apple\"\n",
    "collection_name = \"intraday_r\"\n",
    "\n",
    "# Connect to MongoDB and get the collection\n",
    "client = MongoClient(mongo_uri)\n",
    "db = client[database_name]\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Fetch data from MongoDB and convert ObjectId to string\n",
    "mongo_data = []\n",
    "for doc in collection.find():\n",
    "    if '_id' in doc and isinstance(doc['_id'], ObjectId):\n",
    "        doc['_id'] = str(doc['_id'])\n",
    "    mongo_data.append(doc)\n",
    "\n",
    "# Step 3: Convert MongoDB data to Spark DataFrame\n",
    "df = spark.createDataFrame(mongo_data)\n",
    "\n",
    "# Step 4: Define a window specification to calculate the previous row values\n",
    "window_spec = Window.partitionBy(\"symbol\").orderBy(\"timestamp\")\n",
    "\n",
    "# Calculate the previous volume and price using the lag function\n",
    "df = df.withColumn(\"prev_volume\", lag(\"volume\", 1).over(window_spec))\n",
    "df = df.withColumn(\"prev_price\", lag(\"close\", 1).over(window_spec))\n",
    "\n",
    "# Calculate percent change in volume\n",
    "df = df.withColumn(\"percent_change_volume\", \n",
    "                   expr(\"(volume - prev_volume) / prev_volume * 100\"))\n",
    "\n",
    "# Calculate percent change in price\n",
    "df = df.withColumn(\"percent_change_price\", \n",
    "                   expr(\"(close - prev_price) / prev_price * 100\"))\n",
    "\n",
    "# Step 5: Show the updated DataFrame\n",
    "#df.show(truncate=False)\n",
    "\n",
    "# Convert Spark DataFrame to Pandas\n",
    "df2 = df.toPandas()\n",
    "\n",
    "# Set up S3 client\n",
    "s3_client = boto3.client(\n",
    "    \"s3\",\n",
    "    aws_access_key_id='AWS ACCESS KEY',\n",
    "    aws_secret_access_key='AWS SECRET KEY',\n",
    "    region_name='REGION WHERE S3 BUCKET IS HOSTED'\n",
    ")\n",
    "\n",
    "# Generate a unique filename for S3\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "s3_file_name = f\"AppleIntraday_{timestamp}.csv\"\n",
    "\n",
    "# Specify your S3 bucket name\n",
    "bucket_name = 'apple-intraday'\n",
    "\n",
    "with io.StringIO() as csv_buffer:\n",
    "    df2.to_csv(csv_buffer, index=False)\n",
    "\n",
    "    response = s3_client.put_object(\n",
    "        Bucket=bucket_name, Key=s3_file_name, Body=csv_buffer.getvalue()\n",
    "    )\n",
    "\n",
    "    status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "    if status == 200:\n",
    "        print(f\"Successful S3 put_object response. Status - {status}\")\n",
    "    else:\n",
    "        print(f\"Unsuccessful S3 put_object response. Status - {status}\")\n",
    "\n",
    "print(f\"New file uploaded to S3: s3://{bucket_name}/{s3_file_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210a4966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
